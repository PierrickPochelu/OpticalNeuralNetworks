{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e65b9a9-42d5-471b-bf7c-8d55387ea24e",
   "metadata": {},
   "source": [
    "# Optical Neural Network with numpy/jax\n",
    "\n",
    "Simple example Y=WX\n",
    "![alt text](mzi_mesh.jpg \"Mesh type used\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a17670d-8cbe-4163-b746-ec4651a62b80",
   "metadata": {},
   "source": [
    "## Trainable photonic circuit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f814ba-0810-43e6-b307-cd81238df0d4",
   "metadata": {},
   "source": [
    "###  Noise function according to AnalogVNN formula\n",
    "source: https://arxiv.org/pdf/2210.10048.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2422cadb-33b2-4364-a739-a6159f89f765",
   "metadata": {},
   "source": [
    "![alt text](analogVNN.png \"AnalogVNN big picture figure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "852f1e8f-0b22-47b6-a0fb-59efbc874c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "from jax import numpy as np\n",
    "\n",
    "random_seed=1\n",
    "noisy=True\n",
    "\n",
    "def get_key():\n",
    "    global random_seed\n",
    "    random_seed+=1\n",
    "    return jax.random.PRNGKey(random_seed)\n",
    "\n",
    "def no_back(f): \n",
    "    \"\"\" Decorator to avoid backpropagation of the decorated function.\n",
    "    For example it is useful for \"round(x)\" \"\"\"\n",
    "    def decorated_f(x, *args):\n",
    "        # Create an exactly-zero expression with Sterbenz lemma that has\n",
    "        # an exactly-one gradient.\n",
    "        # URL : https://jax.readthedocs.io/en/latest/jax-101/04-advanced-autodiff.html\n",
    "        zero = x - jax.lax.stop_gradient(x)\n",
    "        return zero + jax.lax.stop_gradient(f(x, *args))\n",
    "    return decorated_f\n",
    "\n",
    "# Previous function implement noise AnalogVNN: https://arxiv.org/pdf/2210.10048.pdf\n",
    "def _rounding_with_thresh(g, r):\n",
    "    g_abs = np.abs(g)\n",
    "    g_floor = np.floor(g_abs)\n",
    "    g_ceil = np.ceil(g_abs)\n",
    "    prob_floor = 1. - np.abs(g_floor - g)\n",
    "    do_floor = np.array( r <= prob_floor, dtype=np.float32)\n",
    "    do_ceil = np.array( r > prob_floor, dtype=np.float32)\n",
    "    return do_floor * g_floor + do_ceil * g_ceil\n",
    "\n",
    "@no_back\n",
    "def precion_reduction(x, p):\n",
    "    \"\"\"warning precision=4 means 5 potential value:  {0,0.25,0.5,0.75,1}\n",
    "    substracting by 1 before calling it is maybe always required\"\"\"\n",
    "    r=0.5\n",
    "    g = x * p\n",
    "    f = np.sign(g) * _rounding_with_thresh(g, r) * (1. / p)\n",
    "    return f\n",
    "\n",
    "@no_back\n",
    "def stochastic_reduce_precision(x, p):\n",
    "    g = x * p\n",
    "    r=jax.random.uniform(shape=x.shape, key=get_key(), dtype=np.float32)\n",
    "    f = np.sign(g) * _rounding_with_thresh(g, r) * (1. / p)\n",
    "    return f\n",
    "\n",
    "def signal_norm(x):\n",
    "    return np.clip(x,-1.,+1.)\n",
    "\n",
    "@no_back\n",
    "def teta_norm(x):\n",
    "    return np.clip(x,-1.,+1.)\n",
    "\n",
    "@no_back\n",
    "def additive_noise(x, std):\n",
    "    noise=jax.random.normal(shape=x.shape, key=get_key(),dtype=np.float32) * std\n",
    "    return x+noise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24860cde-29a2-4f3e-89ed-bc8fc7a3d976",
   "metadata": {},
   "source": [
    "### Circuits: MZI, column of MZI, mesh, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52fe45c5-9abd-4a81-b9ac-7f76117143c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MZI(X, teta):\n",
    "    R = np.array([\n",
    "      [np.cos(teta), -np.sin(teta)],\n",
    "      [np.sin(teta), np.cos(teta)]\n",
    "    ])\n",
    "    out_vector=np.dot(R, X)\n",
    "    return out_vector\n",
    "\n",
    "def noisy_MZI(X, teta):\n",
    "    p_signal=2.**4\n",
    "    p_weights=2.**4\n",
    "    noise_signal=1e-3\n",
    "    noise_weights=1e-3\n",
    "    \n",
    "    X=additive_noise( precion_reduction( signal_norm(X) , p_signal ) , noise_signal)\n",
    "    teta=additive_noise( stochastic_reduce_precision( teta_norm(teta) , p_weights), noise_weights)\n",
    "    \n",
    "    y=MZI(X, teta)\n",
    "\n",
    "    y=precion_reduction( signal_norm( additive_noise(y, noise_signal ) ) , p_signal)\n",
    "\n",
    "    return y\n",
    "\n",
    "def MZI_col(X, nb_mzi, W):\n",
    "    \n",
    "    if noisy:\n",
    "        MZI_strat=noisy_MZI\n",
    "    else:\n",
    "        MZI_strat=MZI\n",
    "    \n",
    "    # Column type: odd or even ?\n",
    "    nb_pins=nb_mzi*2\n",
    "    if nb_pins==len(X):\n",
    "        start_pin_id=0\n",
    "    elif nb_pins+2==len(X):\n",
    "        start_pin_id=1\n",
    "    else:\n",
    "        raise ValueError(\"This mesh patern is not compatible with this input size and #MZIs\")\n",
    "\n",
    "    # pin them\n",
    "    layer_outputs=[]\n",
    "    if start_pin_id==1:\n",
    "        layer_outputs.append(np.array([X[0]]))\n",
    "    \n",
    "    for ID in range(0, nb_mzi):\n",
    "        # take input vector\n",
    "        first_pin_pos=2*ID+start_pin_id\n",
    "        second_pin_pos=first_pin_pos+1\n",
    "        local_inp = X[first_pin_pos:second_pin_pos+1]\n",
    "        \n",
    "        # compute the output vector\n",
    "        local_out=MZI_strat(local_inp, W[ID])\n",
    "        layer_outputs.append(local_out)\n",
    "    \n",
    "    if start_pin_id==1:\n",
    "        layer_outputs.append(np.array([X[-1]]))\n",
    "    \n",
    "    Y=np.concatenate(layer_outputs)\n",
    "    return Y\n",
    "\n",
    "def onn(X, nb_mzis, weights):\n",
    "    nb_layers=len(weights)\n",
    "\n",
    "    def recusive_layer_builder(id_layer=0):\n",
    "        if id_layer==nb_layers-1: # last layer. No dependency\n",
    "            input_shape=X.shape\n",
    "            y=MZI_col(X, nb_mzis[id_layer], weights[id_layer])\n",
    "        else:\n",
    "            y = recusive_layer_builder(id_layer + 1)\n",
    "            input_shape=y.shape\n",
    "            y=MZI_col(y, nb_mzis[id_layer], weights[id_layer])\n",
    "        return y\n",
    "\n",
    "    Y=recusive_layer_builder()\n",
    "    return Y\n",
    "\n",
    "def spec_mesh(cols, mzi_per_col): #e.g. 6,3->3,2,3,2,3,2\n",
    "    cols=n_comp\n",
    "    mzi_per_col=n_comp//2\n",
    "    nb_mzis=[]\n",
    "    for i in range(cols):\n",
    "        nb_mzis.append( mzi_per_col-i%2 )\n",
    "    return nb_mzis\n",
    "\n",
    "def glorot_init(nb_mzi):\n",
    "    weights=jax.random.normal(shape=(nb_mzi,), key=get_key(),dtype=np.float32) * np.sqrt(0.5)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5aac8e-ee3b-49cd-8449-8b3949a74f86",
   "metadata": {},
   "source": [
    "## Simple function learning: [0,1,] -> [1,0]\n",
    "Simple problem before solving harder problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3fc785",
   "metadata": {},
   "source": [
    "#### Configuration of the training dataset and ONN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8582ab7-877e-412f-80eb-b3267fccaf3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "X=np.array([1, 0])\n",
    "Y=np.array([0, 1])\n",
    "nb_MZIs=(1,)\n",
    "W=[]\n",
    "for n in nb_MZIs:\n",
    "    W.append(glorot_init(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312a57c6",
   "metadata": {},
   "source": [
    "#### Backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0039d82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def circuit(X, W):\n",
    "    return onn(X, nb_MZIs, W)\n",
    "    \n",
    "# Create the circuit with metric\n",
    "def circuit_to_opt(*args):\n",
    "    y_=circuit(*args)\n",
    "    loss=np.mean((Y-y_)**2)\n",
    "    return loss\n",
    "\n",
    "deriv_circuit_to_opt=jax.grad(circuit_to_opt, argnums=(-1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418ccc5e-8994-46c6-ac7d-286f4e36e19a",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce64b132-50d1-4b07-a6f8-9b1734479b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First pred.: [ 1.     -0.1875]\n",
      "current loss: 1.2050781\n",
      "current loss: 0.6347656\n",
      "current loss: 0.26757812\n",
      "current loss: 0.17578125\n",
      "current loss: 0.17578125\n",
      "Final pred.: [0.5625 0.8125]\n"
     ]
    }
   ],
   "source": [
    "lr=0.5\n",
    "print(\"First pred.:\", circuit(X,W))\n",
    "for i in range(5):\n",
    "    \n",
    "    # forward phase\n",
    "    print(\"current loss:\", circuit_to_opt(X,W))\n",
    "\n",
    "    # backward phase\n",
    "    dW=deriv_circuit_to_opt(X,W)[0]\n",
    "\n",
    "    # Update using the gradient information\n",
    "    for i, dWi in enumerate(dW):\n",
    "        W[i] = W[i] - lr * dWi\n",
    "print(\"Final pred.:\", circuit(X,W))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f7c163",
   "metadata": {},
   "source": [
    "## On-chip learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b10e40-5bff-4537-a81b-67e41ea7fdff",
   "metadata": {},
   "source": [
    "#### Information about on-chip learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4af6df-dfdf-4c5a-a995-76d53ccef186",
   "metadata": {},
   "source": [
    "* Stochastic Gradient Descent optimization (code below):\n",
    "    * Pros:\n",
    "        * Speed and Scalability when the dimensionality (#params) increase\n",
    "    * Cons: \n",
    "        * Above code need to be embedded on-chip\n",
    "        * Noisy gradient (E.g. MZI noise) -> catastrophic performance (E.g. > 0.001)\n",
    "* Other optimizer exists:\n",
    "    * Example:\n",
    "        * Forward gradient descent\n",
    "        * Simulated annealing\n",
    "        * ...\n",
    "    * Pros:\n",
    "        * Simpler to implement (no backpropagation)\n",
    "    * Cons: \n",
    "        * They do not scale well when the dimensionality increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfa0bdae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: JaxDecompiler in /home/pierrick/program/python3_photon/install/Python-3.8.12/lib/python3.8/site-packages (0.0.3)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 23.0 is available.\n",
      "You should consider upgrading via the '/home/pierrick/program/python3_photon//install/Python-3.8.12/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "import jax\n",
      "from jax.numpy import *\n",
      "from jax._src import prng\n",
      "def f(b, c):\n",
      "    a = array([0, 1], dtype=int32)\n",
      "    d = jax.lax.dynamic_slice_in_dim(c, 0, (1,)[0], axis=0)\n",
      "    e = squeeze(array(d))\n",
      "    def local_f0(a, b, c):\n",
      "        d = array(a).astype(float32)\n",
      "        e = array([max(b)])\n",
      "        f = array([min(c)])\n",
      "        return f\n",
      "    f = local_f0(b, -1.0, 1.0)\n",
      "    g = f # stop grad\n",
      "    h = f - g\n",
      "    i = f * 16.0\n",
      "    def local_f1(a):\n",
      "        b = sign(a)\n",
      "        return b\n",
      "    j = local_f1(i)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install JaxDecompiler\n",
    "import sys\n",
    "import os\n",
    "from JaxDecompiler import decompiler\n",
    "df, c= decompiler.python_jaxpr_python(deriv_circuit_to_opt, (X, W), is_python_returned=True)\n",
    "print(\"\\n\".join(c.split(\"\\n\")[:20])) # print the 20 first lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb341b51-6301-4784-affe-3bdb36403658",
   "metadata": {},
   "source": [
    "## MNIST classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8da22a-4d92-458f-9bec-36f58fca306b",
   "metadata": {},
   "source": [
    "Commonly used dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97a2c43-4473-417b-abfc-7bfceeabc366",
   "metadata": {},
   "source": [
    "#### Read the raw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd4ed0e8-e92f-43f3-a891-ff77d9d2854c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-10 19:12:40.008560: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/pierrick/program/lzma/:/home/pierrick/program/python3_photon//install/Python-3.8.12/lib/:\n",
      "2023-02-10 19:12:47.193056: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/pierrick/program/lzma/:/home/pierrick/program/python3_photon//install/Python-3.8.12/lib/:\n",
      "2023-02-10 19:12:47.193260: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/pierrick/program/lzma/:/home/pierrick/program/python3_photon//install/Python-3.8.12/lib/:\n",
      "2023-02-10 19:12:47.193279: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as npo\n",
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a74ba5-9264-4f63-88d1-bca3234c1be3",
   "metadata": {},
   "source": [
    "#### Preprocessing dataset \n",
    "Croping, interpolating, intensity scaling, reshaping, projection, shuffling..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6489ca84-65ec-4fdf-9dce-6de8e2850b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA variance explained: 0.5216448906637599\n",
      "(60000, 10)\n",
      "(60000, 10)\n",
      "(10000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Cropping\n",
    "train_X=train_X[:,4:24,4:24]\n",
    "test_X=test_X[:,4:24,4:24]\n",
    "#after 20x20\n",
    "\n",
    "# Interpolating\n",
    "from scipy.ndimage import zoom\n",
    "train_X= zoom(train_X,(1.,.5,.5),order=3)  #order = 3 for cubic interpolation\n",
    "test_X= zoom(test_X,(1.,.5,.5),order=3)\n",
    "# after 10x10\n",
    "\n",
    "# intensity scaling and flatting\n",
    "train_X=train_X.reshape((len(train_X),10*10))/255.\n",
    "test_X=test_X.reshape((len(test_X),10*10))/255.\n",
    "\n",
    "# projection\n",
    "n_comp=10 # 10 -> variance explained is only 52%\n",
    "from sklearn.decomposition import PCA\n",
    "proj = PCA(n_components = n_comp)\n",
    "train_X = proj.fit_transform(train_X)\n",
    "test_X=proj.transform(test_X)\n",
    "print(f\"PCA variance explained: {sum(proj.explained_variance_ratio_)}\")\n",
    "\n",
    "# label processing into one-hot vector\n",
    "train_y2=npo.zeros((len(train_X),n_comp),dtype=float)\n",
    "test_y2=npo.zeros((len(test_X),n_comp), dtype=float)\n",
    "for i,v in enumerate(train_y):\n",
    "    train_y2[i][v]=1.\n",
    "\n",
    "for i,v in enumerate(test_y):\n",
    "    test_y2[i][v]=1.\n",
    "\n",
    "# shuffling\n",
    "ids=npo.array(range(len(train_X)))\n",
    "npo.random.shuffle(ids)\n",
    "train_X=train_X[ids]\n",
    "train_y2=train_y2[ids]\n",
    "\n",
    "ids=npo.array(range(len(test_X)))\n",
    "npo.random.shuffle(ids)\n",
    "test_X=test_X[ids]\n",
    "test_y2=test_y2[ids]\n",
    "\n",
    "# Dimension check\n",
    "print(train_X.shape)\n",
    "print(train_y2.shape)\n",
    "print(test_X.shape)\n",
    "print(test_y2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328adb35-82e3-477d-a659-719b56f2b738",
   "metadata": {},
   "source": [
    "#### Definition of the ONN (forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1e8b7e46-6431-4876-9152-24525147136d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init weights\n",
    "nb_mzis=spec_mesh(10, 5)\n",
    "W=[]\n",
    "for n in nb_mzis:\n",
    "    W.append(glorot_init(n))\n",
    "\n",
    "# compilation of the onn\n",
    "def onn10(X, W):\n",
    "    return onn(X, nb_mzis, W)\n",
    "circuit=jax.jit(onn10) # JIT circuit is ~3300 times faster!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b3f996-2b80-4ea6-ba00-1eccdc6cf927",
   "metadata": {},
   "source": [
    "#### Backward definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7b7c3f47-068b-4dbe-b97a-68d279a71839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the circuit with metric\n",
    "def circuit_to_opt(*args):\n",
    "    y_pred=circuit(*(args[0], args[2])) #0:X, 2:W\n",
    "    y_expected=args[1] #1:Y\n",
    "    loss=np.mean((y_expected-y_pred)**2)\n",
    "    return loss\n",
    "\n",
    "deriv_circuit_to_opt=jax.grad(circuit_to_opt, argnums=(-1,))\n",
    "deriv_circuit_to_opt=jax.jit(deriv_circuit_to_opt) # JIT circuit is ~3300 times faster!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87510814-d0f0-4ede-8905-2d72a96073f0",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dd839aaa-e3c1-4e6d-821b-56eac3719ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m st\u001b[38;5;241m=\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# backward phase\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m dW\u001b[38;5;241m=\u001b[39m\u001b[43mderiv_circuit_to_opt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Update using the gradient information\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, dWi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dW):\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/program/python3_photon/install/Python-3.8.12/lib/python3.8/site-packages/jax/_src/api.py:622\u001b[0m, in \u001b[0;36m_cpp_jit.<locals>.cache_miss\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    619\u001b[0m execute \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(top_trace, core\u001b[38;5;241m.\u001b[39mEvalTrace) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[1;32m    621\u001b[0m     jax\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mjax_debug_nans \u001b[38;5;129;01mor\u001b[39;00m jax\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mjax_debug_infs):\n\u001b[0;32m--> 622\u001b[0m   execute \u001b[38;5;241m=\u001b[39m \u001b[43mdispatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_xla_call_impl_lazy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtracers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    623\u001b[0m   out_flat \u001b[38;5;241m=\u001b[39m call_bind_continuation(execute(\u001b[38;5;241m*\u001b[39margs_flat))\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/program/python3_photon/install/Python-3.8.12/lib/python3.8/site-packages/jax/_src/dispatch.py:241\u001b[0m, in \u001b[0;36m_xla_call_impl_lazy\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDynamic shapes do not work with Array.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    240\u001b[0m   arg_specs \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mgetattr\u001b[39m(x, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_device\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[0;32m--> 241\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mxla_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdonated_invars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marg_specs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/program/python3_photon/install/Python-3.8.12/lib/python3.8/site-packages/jax/linear_util.py:303\u001b[0m, in \u001b[0;36mcache.<locals>.memoized_fun\u001b[0;34m(fun, *args)\u001b[0m\n\u001b[1;32m    301\u001b[0m   fun\u001b[38;5;241m.\u001b[39mpopulate_stores(stores)\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 303\u001b[0m   ans \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    304\u001b[0m   cache[key] \u001b[38;5;241m=\u001b[39m (ans, fun\u001b[38;5;241m.\u001b[39mstores)\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ans\n",
      "File \u001b[0;32m~/program/python3_photon/install/Python-3.8.12/lib/python3.8/site-packages/jax/_src/dispatch.py:359\u001b[0m, in \u001b[0;36m_xla_callable_uncached\u001b[0;34m(fun, device, backend, name, donated_invars, keep_unused, *arg_specs)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mjax_array:\n\u001b[1;32m    357\u001b[0m   computation \u001b[38;5;241m=\u001b[39m sharded_lowering(fun, device, backend, name, donated_invars,\n\u001b[1;32m    358\u001b[0m                                  \u001b[38;5;28;01mFalse\u001b[39;00m, keep_unused, \u001b[38;5;241m*\u001b[39marg_specs)\n\u001b[0;32m--> 359\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomputation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_allow_propagation_to_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39munsafe_call\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    361\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m lower_xla_callable(fun, device, backend, name, donated_invars, \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    362\u001b[0m                             keep_unused, \u001b[38;5;241m*\u001b[39marg_specs)\u001b[38;5;241m.\u001b[39mcompile()\u001b[38;5;241m.\u001b[39munsafe_call\n",
      "File \u001b[0;32m~/program/python3_photon/install/Python-3.8.12/lib/python3.8/site-packages/jax/interpreters/pxla.py:3202\u001b[0m, in \u001b[0;36mMeshComputation.compile\u001b[0;34m(self, _allow_propagation_to_outputs, _allow_compile_replicated)\u001b[0m\n\u001b[1;32m   3198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompile\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   3199\u001b[0m             _allow_propagation_to_outputs : \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   3200\u001b[0m             _allow_compile_replicated : \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m MeshExecutable:\n\u001b[1;32m   3201\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executable \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 3202\u001b[0m     executable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compile_unloaded\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3203\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_allow_propagation_to_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_allow_compile_replicated\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3204\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(executable, UnloadedMeshExecutable):\n\u001b[1;32m   3205\u001b[0m       executable \u001b[38;5;241m=\u001b[39m executable\u001b[38;5;241m.\u001b[39mload()\n",
      "File \u001b[0;32m~/program/python3_photon/install/Python-3.8.12/lib/python3.8/site-packages/jax/interpreters/pxla.py:3170\u001b[0m, in \u001b[0;36mMeshComputation._compile_unloaded\u001b[0;34m(self, _allow_propagation_to_outputs, _allow_compile_replicated)\u001b[0m\n\u001b[1;32m   3168\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m MeshExecutable\u001b[38;5;241m.\u001b[39mfrom_trivial_jaxpr(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompile_args)\n\u001b[1;32m   3169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3170\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mUnloadedMeshExecutable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_hlo\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3171\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3172\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_hlo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3173\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3174\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_allow_propagation_to_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_allow_propagation_to_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3175\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_allow_compile_replicated\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_allow_compile_replicated\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/program/python3_photon/install/Python-3.8.12/lib/python3.8/site-packages/jax/interpreters/pxla.py:3439\u001b[0m, in \u001b[0;36mUnloadedMeshExecutable.from_hlo\u001b[0;34m(name, computation, mesh, global_in_avals, global_out_avals, in_shardings, out_shardings, spmd_lowering, tuple_args, in_is_global, auto_spmd_lowering, _allow_propagation_to_outputs, _allow_compile_replicated, unordered_effects, ordered_effects, host_callbacks, keepalive, kept_var_idx, backend, device_assignment, committed, pmap_nreps)\u001b[0m\n\u001b[1;32m   3435\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3436\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m dispatch\u001b[38;5;241m.\u001b[39mlog_elapsed_time(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished XLA compilation of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3437\u001b[0m                                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min \u001b[39m\u001b[38;5;132;01m{elapsed_time}\u001b[39;00m\u001b[38;5;124m sec\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3438\u001b[0m                                  event\u001b[38;5;241m=\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mBACKEND_COMPILE_EVENT):\n\u001b[0;32m-> 3439\u001b[0m     xla_executable \u001b[38;5;241m=\u001b[39m \u001b[43mdispatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_or_get_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomputation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompile_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost_callbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3442\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m auto_spmd_lowering:\n\u001b[1;32m   3443\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m mesh \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/program/python3_photon/install/Python-3.8.12/lib/python3.8/site-packages/jax/_src/dispatch.py:1079\u001b[0m, in \u001b[0;36mcompile_or_get_cached\u001b[0;34m(backend, computation, compile_options, host_callbacks)\u001b[0m\n\u001b[1;32m   1075\u001b[0m     _cache_write(serialized_computation, compile_time, module_name,\n\u001b[1;32m   1076\u001b[0m                  compile_options, backend, compiled)\n\u001b[1;32m   1077\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m compiled\n\u001b[0;32m-> 1079\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserialized_computation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompile_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mhost_callbacks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/program/python3_photon/install/Python-3.8.12/lib/python3.8/site-packages/jax/_src/profiler.py:314\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    313\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n",
      "File \u001b[0;32m~/program/python3_photon/install/Python-3.8.12/lib/python3.8/site-packages/jax/_src/dispatch.py:1014\u001b[0m, in \u001b[0;36mbackend_compile\u001b[0;34m(backend, built_c, options, host_callbacks)\u001b[0m\n\u001b[1;32m   1009\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mcompile(built_c, compile_options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   1010\u001b[0m                          host_callbacks\u001b[38;5;241m=\u001b[39mhost_callbacks)\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;66;03m# Some backends don't have `host_callbacks` option yet\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m \u001b[38;5;66;03m# TODO(sharadmv): remove this fallback when all backends allow `compile`\u001b[39;00m\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;66;03m# to take in `host_callbacks`\u001b[39;00m\n\u001b[0;32m-> 1014\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuilt_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompile_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "random_seed=1\n",
    "lr=0.1\n",
    "import time\n",
    "for e in range(5): # for each epoch\n",
    "    \n",
    "    # Data shuffling\n",
    "    ids=npo.array(range(len(train_X)))\n",
    "    npo.random.shuffle(ids)\n",
    "    train_X=train_X[ids]\n",
    "    train_y2=train_y2[ids]\n",
    "    print(\"start\")\n",
    "    \n",
    "    # Training\n",
    "    for X,Y in zip(train_X, train_y2): # for each data sample\n",
    "        st=time.time()\n",
    "        # backward phase\n",
    "        dW=deriv_circuit_to_opt(X, Y, W)[0]\n",
    "\n",
    "        # Update using the gradient information\n",
    "        for i, dWi in enumerate(dW):\n",
    "            W[i] = W[i] - lr * dWi\n",
    "        #print(time.time()-st) # 0.002 after JIT\n",
    "    # Evaluation\n",
    "    nb_correct=0\n",
    "    for X,Y in zip(test_X, test_y2):        \n",
    "        y_pred=circuit(X, W)\n",
    "        nb_correct+=np.argmax(y_pred)==np.argmax(Y)\n",
    "    print(f\"accuracy:{float(nb_correct)/len(test_y2)}\")\n",
    "    lr/=10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3acefc8",
   "metadata": {},
   "source": [
    "#### Ensemble of ONN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c62428aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model 0: 0.4347\n",
      "Accuracy of the model 1: 0.3755\n",
      "Accuracy of the model 2: 0.4251\n",
      "Accuracy of the model 3: 0.4344\n",
      "Accuracy of the model 4: 0.4163\n",
      "Ensemble accuracy: 0.5884\n"
     ]
    }
   ],
   "source": [
    "nb_mzis=spec_mesh(10, 5)\n",
    "lr=0.1\n",
    "\n",
    "Ensemble_W=[]\n",
    "for ens in range(5):\n",
    "    \n",
    "    W2=[]\n",
    "    for n in nb_mzis:\n",
    "        W2.append(glorot_init(n))\n",
    "    \n",
    "    # Data shuffling\n",
    "    ids=npo.array(range(len(train_X)))\n",
    "    npo.random.shuffle(ids)\n",
    "    train_X=train_X[ids]\n",
    "    train_y2=train_y2[ids]\n",
    "    \n",
    "    #training\n",
    "    for X,Y in zip(train_X, train_y2): # for each data sample\n",
    "        \n",
    "        start_time=time.time()\n",
    "        # backward phase\n",
    "        dW=deriv_circuit_to_opt(X, Y, W2)[0]\n",
    "\n",
    "        # Update using the gradient information\n",
    "        for i, dWi in enumerate(dW):\n",
    "            W2[i] = W2[i] - lr * dWi\n",
    "        print(time.time()-start_time)\n",
    "        \n",
    "    # Evaluation\n",
    "    nb_correct=0\n",
    "    for X,Y in zip(test_X, test_y2):        \n",
    "        y_pred=circuit(X, W2)\n",
    "        nb_correct+=np.argmax(y_pred)==np.argmax(Y)\n",
    "    print(f\"Accuracy of the model {ens}: {float(nb_correct)/len(test_y2)}\")\n",
    "\n",
    "    Ensemble_W.append(W2)\n",
    "    \n",
    "# Ensemble evaluation\n",
    "nb_correct=0\n",
    "for X,Y in zip(test_X, test_y2):        \n",
    "    y_pred=np.average(np.array([circuit(X, Wi) for Wi in Ensemble_W]),axis=0)\n",
    "    nb_correct+=np.argmax(y_pred)==np.argmax(Y)\n",
    "print(f\"Ensemble accuracy: {float(nb_correct)/len(test_y2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18ed666-1031-48f5-a7ab-658cbfa1e5a1",
   "metadata": {},
   "source": [
    "Conclusion about the ensemble (with no noise):\n",
    "\n",
    "    * The ensemble is better than base ONN in it\n",
    "    * An ensemble of 5 base ONNs trained 1 epoch (67.56%) > 1 ONN trained 5 epochs (66.91%)  -> Better usage of computing ressources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daa7c5c-b75a-4709-a640-a0ec46678837",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
